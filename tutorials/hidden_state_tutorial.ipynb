{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f1567b-431f-4948-8b6a-6952defb9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64555d54-2a9f-4384-9204-63d2b1b7cd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e35829298f64719b60b6d582b1f301d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ad7743-1288-4abb-b569-5f5c18ee2ccc",
   "metadata": {},
   "source": [
    "**From Claude**: using named_parameters which is a typical pytorch Module method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5183367-3722-4172-b854-14097dbce26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = {}\n",
    "for name, param in model.named_parameters():\n",
    "    # Filter for specific layers you're interested in\n",
    "    if \"layer\" in name and \"self_attn\" in name:\n",
    "        # This gives you access to the parameter values\n",
    "        activations[name] = param.data\n",
    "        # print(f\"Layer: {name}, Shape: {activation.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ea3d11-8cfc-4fac-9bb5-c6b466da90af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 'model.layers.0.self_attn.q_proj.weight')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(activations.keys()),list(activations.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ce69a-1dba-4c2e-9c4d-44920529686b",
   "metadata": {},
   "source": [
    "Okay, I can easily find all the parametric weights of the model. But perhaps what I want are the hidden states. Think about in a regular NN model: you have weights before evaluating an input, but the hidden states are dependent on the input and all the weights.\n",
    "\n",
    "So I need to input a text into the LLM, and it'll pass through and get affected by the LLM's weights. And there should be a residual stream hidden state $h_i^{(l)}$, and attention hidden states $a_i^{(l)}$ for every token $i$ and layer $l$.\n",
    "\n",
    "Let's try to extract hidden states for a simple model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f70cbe0e-504e-41cb-8b51-976f0d0160d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b951fa8-640b-4bad-9c23-198a5d9e573f",
   "metadata": {},
   "source": [
    "We need to modify the model slightly to also return hidden states. In RNNs, we usually return these hidden states too during the forward pass, rather than just returning the final output layer.\n",
    "\n",
    "Note that in LLMs, the output of the forward is typically just the logits or some dictionary containing multiple things. We need to see if that already has the hidden states, else we need to modify it to return some specific hidden states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fe893b-de92-4503-9cd4-6e32133cc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden1 = F.relu(self.conv1(x))\n",
    "        hidden2 = F.relu(self.conv2(hidden1))\n",
    "        return hidden2, (hidden1, hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2f2892-47e8-4273-b2f5-8a0c36631bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and use the model\n",
    "model = Model()\n",
    "input_tensor = torch.randn(1, 1, 28, 28)  # Example input tensor\n",
    "output, (hidden1, hidden2) = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c83fdfdc-04c1-4b7a-bc0c-b6da450597ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]),\n",
       " torch.Size([1, 20, 24, 24]),\n",
       " torch.Size([1, 20, 20, 20]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.shape,hidden1.shape,hidden2.shape # (c=1,28,28) -> (c=20,24,24) -> (c=20,20,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c66014-026c-42a8-a9e4-18f8c2649054",
   "metadata": {},
   "source": [
    "In more complex models where we don't want to modify the internal structure, we use hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8846096-dedc-4876-97e7-1a78206a89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7232a12-f3c3-4b4f-852f-43d430dc51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "activations = {}\n",
    "all_trials = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c58de2a-0c56-4ff0-b2be-f46ee708d559",
   "metadata": {},
   "source": [
    "The hook will be called every time after forward() has computed an output. It should have the following signature:\n",
    "\n",
    "```\n",
    "hook(module, input, output) -> None or modified output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f24e6f0d-5236-4526-9a0e-e845edf892c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a hook function\n",
    "def get_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "764ed891-7908-422b-9e60-dd35095a6673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 20])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.register_forward_hook(get_hook('conv1'))\n",
    "model.conv2.register_forward_hook(get_hook('conv2'))\n",
    "# Registers a hook onto conv1 layer, so whenever the conv1 layer forward is executed, the hook executes.\n",
    "# Within the hook, outputs of the conv1 layer are stored into the activations dict.\n",
    "# So if I run a forward pass through the model regularly, the output will be as expected...\n",
    "# ... but now, I'll get the internal hidden states too.\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "output = model(input_tensor)\n",
    "all_trials.append(activations.copy())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383cfccc-fcbf-4d76-8a43-500cd150ae83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_trials' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_trials\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_trials' is not defined"
     ]
    }
   ],
   "source": [
    "all_trials[0]['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c01ce7a0-b27d-41ee-8ea5-3d5d397f2b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "output = model(input_tensor)\n",
    "all_trials.append(activations.copy())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fda9edc-bd87-4ebe-9745-06720ef9987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "126857ee-05be-4c2e-add0-7e4ba58d0093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.1241e-01,  2.0024e-02,  3.1108e-01,  ..., -8.6740e-01,\n",
       "            6.9576e-01,  7.4052e-01],\n",
       "          [ 3.3542e-01, -1.8380e-01,  4.4050e-01,  ..., -8.3235e-01,\n",
       "            7.0154e-01,  4.6462e-01],\n",
       "          [-2.7553e-01,  2.2399e-01,  4.9891e-01,  ..., -2.7639e-01,\n",
       "            3.8434e-01,  1.5652e-01],\n",
       "          ...,\n",
       "          [-5.5446e-03, -6.9823e-01, -1.0601e-01,  ..., -8.9663e-02,\n",
       "           -7.7638e-01,  2.0911e-02],\n",
       "          [ 6.3133e-01, -2.2557e-01, -3.1841e-01,  ...,  1.3433e+00,\n",
       "           -1.5430e-01,  1.0233e-01],\n",
       "          [ 1.7771e+00,  1.1866e+00, -4.9348e-01,  ...,  7.0751e-01,\n",
       "           -6.0858e-03, -8.6562e-02]],\n",
       "\n",
       "         [[ 1.6632e-01, -3.9560e-02, -4.2178e-01,  ..., -5.7374e-01,\n",
       "            2.9578e-01,  2.4647e-01],\n",
       "          [-2.6613e-01,  3.2964e-01,  1.9205e-01,  ...,  8.8782e-01,\n",
       "            3.4784e-01,  1.7670e-01],\n",
       "          [ 1.8674e-01,  6.2596e-01,  3.0700e-02,  ...,  3.8379e-01,\n",
       "           -5.2186e-01, -1.3627e-01],\n",
       "          ...,\n",
       "          [ 9.2101e-01,  2.0250e-02, -4.8699e-01,  ..., -4.5807e-01,\n",
       "           -1.0373e+00, -4.3010e-01],\n",
       "          [ 1.2269e+00,  7.8350e-01, -5.1186e-02,  ...,  1.0182e+00,\n",
       "            2.3706e-01, -6.1375e-02],\n",
       "          [-1.6479e-01,  6.8592e-01, -1.2649e-01,  ...,  2.4503e-01,\n",
       "            3.4490e-02, -1.1131e+00]],\n",
       "\n",
       "         [[-5.0887e-01, -1.8373e-01,  2.4102e-02,  ...,  1.0714e-01,\n",
       "            1.2007e-01, -4.0670e-01],\n",
       "          [-4.3859e-01,  1.0838e-01,  3.7978e-01,  ..., -6.3317e-01,\n",
       "            2.3280e-01, -1.9423e-01],\n",
       "          [-2.8461e-01, -4.3392e-02, -5.1017e-01,  ...,  5.7577e-01,\n",
       "           -2.4165e-01,  1.0360e+00],\n",
       "          ...,\n",
       "          [ 7.2161e-01, -1.1017e-03, -7.2059e-01,  ...,  4.1832e-01,\n",
       "            2.2491e-01,  2.8294e-01],\n",
       "          [ 9.6967e-01, -4.0632e-01, -3.1889e-02,  ...,  2.1356e-01,\n",
       "           -5.8484e-01, -7.3487e-01],\n",
       "          [ 1.2046e+00,  2.0879e-01, -1.2794e+00,  ...,  6.7585e-01,\n",
       "           -9.4343e-02, -6.1861e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.1876e-03,  6.1637e-01, -7.5597e-01,  ..., -4.1084e-01,\n",
       "           -3.7210e-01, -1.0722e-01],\n",
       "          [-8.4197e-01, -5.6606e-01,  9.1981e-01,  ..., -5.1313e-01,\n",
       "            9.5366e-01, -4.9263e-01],\n",
       "          [ 7.9401e-01, -5.0099e-01, -5.3127e-01,  ..., -2.6380e-01,\n",
       "           -1.2932e-01,  5.8856e-02],\n",
       "          ...,\n",
       "          [-3.6545e-01,  6.5711e-01, -4.7326e-01,  ...,  7.3439e-01,\n",
       "            3.9445e-02, -2.5755e-01],\n",
       "          [-2.1432e-01, -1.4040e+00,  1.2714e+00,  ..., -6.2001e-01,\n",
       "           -8.3634e-01,  2.5520e-01],\n",
       "          [ 7.3336e-01, -3.2310e-01, -8.2483e-01,  ...,  1.3986e+00,\n",
       "            1.6146e-01, -2.7502e-01]],\n",
       "\n",
       "         [[-2.2202e-01,  1.8190e-01, -4.8590e-01,  ...,  2.5282e-01,\n",
       "           -2.7765e-01, -2.4868e-01],\n",
       "          [-1.9534e-02, -4.1559e-01, -2.7323e-02,  ..., -3.3452e-01,\n",
       "            1.3657e-01,  2.1441e-01],\n",
       "          [ 1.9595e-01,  1.0576e-02, -6.0213e-01,  ...,  4.0732e-01,\n",
       "           -3.7557e-01, -6.6024e-01],\n",
       "          ...,\n",
       "          [-6.6844e-01,  4.6026e-01, -5.2794e-03,  ..., -7.1321e-01,\n",
       "            6.7708e-02,  8.7846e-02],\n",
       "          [-3.0871e-02, -8.5692e-01,  5.7606e-01,  ..., -2.0290e-01,\n",
       "           -2.9034e-01,  2.6856e-01],\n",
       "          [-2.2444e-01,  8.7310e-01,  2.6457e-01,  ...,  1.1798e-01,\n",
       "           -1.8973e-01, -5.4282e-01]],\n",
       "\n",
       "         [[ 3.5443e-01, -5.6901e-01, -5.8383e-02,  ...,  4.2367e-02,\n",
       "            8.4766e-01,  9.2991e-01],\n",
       "          [-3.0968e-01,  1.1762e-01,  7.3372e-01,  ...,  1.0773e+00,\n",
       "            5.0435e-01, -6.5945e-01],\n",
       "          [ 6.4744e-01, -2.9956e-01,  3.6321e-01,  ..., -5.5599e-02,\n",
       "           -8.0199e-01,  2.3907e-01],\n",
       "          ...,\n",
       "          [-1.9544e-01, -6.0222e-02,  7.2769e-01,  ...,  1.6083e-01,\n",
       "           -4.0249e-01, -2.3596e-01],\n",
       "          [-2.9529e-01,  9.6607e-01,  8.1600e-01,  ...,  1.1053e+00,\n",
       "            1.3352e+00,  2.0923e-01],\n",
       "          [ 1.0817e-01, -2.3441e-01, -7.5169e-02,  ..., -4.0444e-01,\n",
       "           -7.9484e-01, -5.3258e-01]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trials[1]['conv1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91e78d-d413-4c9e-bbcf-b7912aa9284c",
   "metadata": {},
   "source": [
    "It's as expected: \n",
    "```\n",
    "(c=1,28,28) [input[ -> (c=20,24,24) -> (c=20,20,20) [output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ecf2eb-0c5b-45e8-bfc5-6c3a3c879a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
