{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f3da553-e6a4-4f18-a12a-f51ef5d77ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19fac011-02b2-41b3-aeaa-c563f9a95407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a8eda05-4e5b-4c57-b27b-b3b99746bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "activations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "754e48b3-a364-49f7-a16f-a62d32b5135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1_hook(model, input, output):\n",
    "    activations[\"conv1\"] = output.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c832bf6d-186a-4973-9e35-3bd0fad0aa60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 20])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.register_forward_hook(conv1_hook)\n",
    "\n",
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "output = model(input_tensor)\n",
    "all_trials.append(activations.copy())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbb7163d-192d-49f0-af99-7de6239e924b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 24, 24])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[\"conv1\"].shape # (c=1,28,28) -> (c=20,24,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52e9b5ce-d796-4b1b-9e32-8c0d5945e068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_and_output(model,x,modification):\n",
    "    _ = model(x) # activations[\"conv1\"] is set here. shape = (1,20,24,24)\n",
    "    modified_activations = activations[\"conv1\"] + modification # modification is also (1,20,24,24)\n",
    "    output = F.relu(model.conv2(modified_activations)) \n",
    "    # The problem with the above step is we need to know how the model was defined and run individually.\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0dd624e2-1608-4626-9a6e-9063c2336f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 20])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "output1 = modify_and_output(model,input_tensor,modification=torch.randn(1,20,24,24))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90aafe8e-e680-448f-989f-ce605632fbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 20, 20])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "output2 = model(input_tensor)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da39606b-2394-4575-a7be-3deff906aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two outputs are not identical due to the modification\n"
     ]
    }
   ],
   "source": [
    "assert not all((output1==output2).squeeze(0).view(-1).tolist())\n",
    "print(\"The two outputs are not identical due to the modification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453ed519-5fc2-4b0f-b477-1cbe8ff89ce5",
   "metadata": {},
   "source": [
    "How do we apply this to the LLM? Basically, get the activation of all tokens at a specific layer. Then apply the modification (in the direction of the context vector) only to the last token. So the modification tensor should be zero in all other tokens and only have a value at that token. It is a (tokens, 4096) vector where only \\[-1,:\\] has non-zero values.\n",
    "\n",
    "So you add that to that specific layer and execute the rest of the LLM using the modified activation.\n",
    "\n",
    "But how do you execute the rest of the LLM? That might require internal modifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
