{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6197672-f1a0-4226-86be-827f8076cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/nikhilanand/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/nikhilanand/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nikhilanand/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from common_methods import *\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "913ca59c-61df-4f6f-9693-bd0f1cdbd5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs,plain_inputs,context_outputs,outputs = load_memotrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c713062f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cf4ab4-8fa3-45f5-a842-3f4dc4f374c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05df192851114523a931b56c3cdb47ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "activations = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bbdf2cc-0349-497c-8f75-33555c8f3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hook(layer_num):\n",
    "    def hook(model,input,output):\n",
    "        activations[layer_num] = output[0].detach() # not just last token, entire set of activations\n",
    "    return hook\n",
    "\n",
    "layer_list = [4,8,16,18,20,22,24,26,28,30,31,32]\n",
    "for i in layer_list:\n",
    "    model.model.layers[i-1].register_forward_hook(get_hook(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbc259b-24d5-434b-a3ed-960f61162a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a quote that ends in the word \"fur\": A rag and a bone and a hank of'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee1079-0120-4c59-ab5b-093d425d6250",
   "metadata": {},
   "source": [
    "The first few tokens have their activations constant while after the prompt starts to change, different prompts evoke different activations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61686832-0263-4c32-9783-37648975ca42",
   "metadata": {},
   "source": [
    "Pass anything into the LM Head to get the output logits and then put softmax on that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3733f471-79f3-4570-8358-1103e6afb34f",
   "metadata": {},
   "source": [
    "- So I have a variable number of intoken positions but a fixed number of layers. Make a 2D matrix for each prompt (intokens x layers).\n",
    "- For each (intoken, layer)-coordinate position, I will write a number that represents the probability of the target token (context_output and default_output, one plot for each).\n",
    "- Do a softmax across the rows of that matrix.\n",
    "- Make heatmaps and save the plots in folders for each prompt. Token word strings should be mentioned on the X-axis. Y-axis has the layer numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "597ed46c-8480-47f1-9ae2-218242768144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/sensei-fs/users/nikhilanand/my_context_layer_decoding/pipeline/common_methods.py:121: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  last_token_probs = F.softmax(last_token_logits)\n"
     ]
    }
   ],
   "source": [
    "out = regular_decoding(model,tokenizer,inputs[0],debug=False,max_tokens=1,show_tqdm=True, return_prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43c3cb2-c7b6-4c7f-bd77-135a6af33e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Write a quote that ends in the word \"fur\": A rag and a bone and a hank of',\n",
       " 'hair')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0],out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5dfa511-1df9-44cd-8c68-c6812adf7930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1450, -0.3086, -0.0419,  ..., -0.0010,  0.0010,  0.0802],\n",
       "         [ 0.4111, -0.5464, -0.0333,  ...,  0.0527, -0.3110,  0.4009],\n",
       "         [ 0.2130, -0.0696,  0.2612,  ...,  0.0239, -0.2042,  0.4705],\n",
       "         ...,\n",
       "         [ 0.1298,  0.0510,  0.1823,  ..., -0.1677,  0.1282, -0.1010],\n",
       "         [-0.1219, -0.0835,  0.1846,  ...,  0.1719,  0.0908, -0.1587],\n",
       "         [-0.0696,  0.1281, -0.0679,  ..., -0.0950, -0.2351,  0.2556]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e152bb9b-1598-43ca-8226-87547fcb52ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=32000, bias=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbe66827-a7bc-429b-9f6b-6d5e3b79aa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 22, 4096])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[26].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7a4ca2a-caa4-44d1-bc94-caec8032bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens_activns = activations[26][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "46233a0e-7134-4229-8b1d-98bedab8867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_list = tokenizer.batch_decode(tokenizer(inputs[0]).input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d47e2e22-5f96-4ee8-b3e6-1a4d44ec8613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 'ends')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_token_list),input_token_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "66b4b804-d5ba-467a-a60e-cba5d32fb2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2982 3691\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fur', 'hair']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordC = \"fur\"\n",
    "wordM = \"hair\"\n",
    "wordC_tok,wordM_tok = tokenizer(wordC).input_ids[1],tokenizer(wordM).input_ids[1]\n",
    "print(wordC_tok,wordM_tok)\n",
    "tokenizer.batch_decode([2982,3691])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb207b87-959a-40ed-bbe5-0c8c3487f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixC = torch.zeros((len(layer_list),len(input_token_list)))\n",
    "matrixM = torch.zeros((len(layer_list),len(input_token_list)))\n",
    "\n",
    "for l in range(len(layer_list)):\n",
    "    for i in range(len(input_token_list)):\n",
    "        layer = layer_list[l]\n",
    "        act = F.softmax(model.lm_head(model.model.norm(activations[layer][0,i,:])),dim=0)\n",
    "        probC = act[wordC_tok]\n",
    "        probM = act[wordM_tok]\n",
    "        \n",
    "        matrixC[l,i] = probC\n",
    "        matrixM[l,i] = probM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5cdb7abd-5eae-4e8f-bfb9-1cbfddda1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5259e-05, 5.0366e-05, 2.7716e-05, 7.6890e-06, 8.8274e-05, 1.5020e-05,\n",
       "         2.2840e-04, 8.3148e-05, 3.2425e-05, 2.3735e-04, 8.2731e-04, 5.0449e-04,\n",
       "         3.1829e-05, 1.1128e-04, 6.5327e-05, 1.0443e-04, 1.5080e-05, 1.3351e-05,\n",
       "         8.6963e-05, 8.7798e-05, 3.4070e-04, 2.9981e-05],\n",
       "        [1.5199e-05, 2.8396e-04, 3.0398e-05, 7.0930e-06, 7.4983e-05, 2.2352e-05,\n",
       "         4.4942e-05, 1.7679e-04, 1.4222e-04, 5.6028e-05, 4.4899e-03, 2.0294e-03,\n",
       "         7.0095e-05, 2.6836e-03, 1.0166e-03, 2.9421e-04, 2.7013e-04, 6.7294e-05,\n",
       "         1.6522e-04, 1.7703e-04, 8.2970e-04, 2.5249e-04],\n",
       "        [1.5080e-05, 1.3959e-04, 3.4988e-05, 1.9610e-05, 1.8597e-05, 5.1439e-05,\n",
       "         5.5909e-05, 6.6817e-05, 6.4075e-05, 3.2365e-05, 3.0565e-04, 6.2180e-04,\n",
       "         6.1274e-05, 5.5075e-04, 4.3821e-04, 9.3460e-04, 2.8133e-04, 1.6427e-04,\n",
       "         2.5320e-04, 1.1456e-04, 4.8542e-04, 1.0033e-03],\n",
       "        [1.5020e-05, 1.0663e-04, 3.0100e-05, 1.4424e-05, 1.8179e-05, 8.6427e-06,\n",
       "         3.9160e-05, 5.9187e-05, 5.3942e-05, 5.2273e-05, 5.7983e-04, 1.0023e-03,\n",
       "         2.9564e-04, 4.4227e-04, 2.0647e-04, 1.2982e-04, 2.2936e-04, 2.2507e-04,\n",
       "         3.4881e-04, 2.5153e-04, 6.2704e-04, 9.4271e-04],\n",
       "        [1.6034e-05, 7.0095e-04, 3.4511e-05, 7.6890e-06, 8.8215e-06, 1.1444e-05,\n",
       "         6.3241e-05, 1.4722e-05, 8.7738e-05, 3.4928e-05, 4.9927e-02, 3.1952e-02,\n",
       "         1.3418e-03, 5.4121e-04, 2.0905e-03, 1.8606e-03, 2.3580e-04, 6.5899e-04,\n",
       "         9.3603e-04, 1.6346e-03, 1.4248e-03, 1.3657e-03],\n",
       "        [1.6212e-05, 3.1853e-04, 2.5809e-05, 4.3511e-06, 3.1590e-06, 2.1458e-06,\n",
       "         3.5644e-05, 5.9605e-07, 1.1265e-05, 2.3007e-05, 1.6150e-01, 4.2480e-02,\n",
       "         4.4518e-03, 1.9848e-04, 1.7441e-02, 6.1493e-03, 5.8556e-04, 1.0815e-03,\n",
       "         9.5224e-04, 1.0424e-03, 1.1673e-03, 1.8845e-03],\n",
       "        [1.6272e-05, 3.9339e-04, 1.6391e-05, 6.6757e-06, 1.8477e-06, 3.9935e-06,\n",
       "         1.5616e-05, 4.1723e-07, 1.3113e-05, 5.2452e-05, 8.5107e-01, 5.8594e-01,\n",
       "         7.1945e-03, 3.4690e-05, 6.7383e-02, 8.4229e-03, 5.6124e-04, 1.0757e-03,\n",
       "         1.1377e-03, 1.7843e-03, 3.6011e-03, 6.8398e-03],\n",
       "        [1.6451e-05, 7.9727e-04, 2.9743e-05, 5.9009e-06, 1.6093e-06, 1.9073e-06,\n",
       "         1.2875e-05, 4.1723e-07, 3.1292e-05, 7.1228e-05, 9.2822e-01, 7.6953e-01,\n",
       "         1.0944e-01, 2.0313e-04, 6.4880e-02, 9.3765e-03, 6.4707e-04, 7.4148e-04,\n",
       "         4.5347e-04, 1.4753e-03, 3.3112e-03, 4.2572e-03],\n",
       "        [1.6332e-05, 6.8521e-04, 3.4571e-05, 6.3181e-06, 0.0000e+00, 8.9407e-07,\n",
       "         7.6890e-06, 3.5763e-07, 1.7881e-05, 7.4089e-05, 7.5830e-01, 4.1577e-01,\n",
       "         1.4856e-01, 2.7657e-04, 2.3468e-02, 1.6890e-03, 1.4076e-03, 9.3746e-04,\n",
       "         4.4823e-04, 1.3428e-03, 4.2305e-03, 7.5912e-04],\n",
       "        [1.6451e-05, 1.9383e-04, 1.5259e-05, 9.5367e-07, 5.9605e-07, 5.9605e-08,\n",
       "         5.3644e-07, 2.3842e-07, 6.0201e-06, 1.9610e-05, 5.5656e-03, 1.0481e-03,\n",
       "         2.2812e-03, 6.0415e-04, 3.3331e-04, 6.6698e-05, 2.7275e-04, 1.9388e-03,\n",
       "         1.3371e-03, 3.4904e-04, 6.7043e-04, 7.0251e-02],\n",
       "        [1.8120e-05, 4.0531e-05, 1.2219e-05, 4.1723e-07, 9.5367e-07, 5.9605e-08,\n",
       "         2.9802e-07, 4.7684e-07, 1.0669e-05, 3.3975e-06, 4.1986e-04, 1.0490e-03,\n",
       "         7.8506e-03, 3.2139e-04, 8.8120e-03, 1.4353e-04, 1.1724e-04, 8.1100e-03,\n",
       "         1.7380e-02, 2.6512e-04, 5.4073e-04, 3.4619e-01],\n",
       "        [0.0000e+00, 4.9472e-06, 1.0490e-05, 3.5763e-07, 2.6822e-06, 1.1921e-07,\n",
       "         6.5565e-07, 2.9802e-07, 1.9550e-05, 5.9605e-08, 1.0967e-05, 1.0312e-05,\n",
       "         4.6501e-03, 5.7817e-06, 3.5167e-05, 1.1921e-07, 4.7684e-07, 4.8280e-06,\n",
       "         7.4744e-05, 0.0000e+00, 6.5565e-07, 4.7913e-03]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c5c7a96-39be-4286-9783-417b8eddf91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8895e-05, 1.8358e-05, 3.3379e-05, 2.7359e-05, 4.4107e-05, 3.7014e-05,\n",
       "         2.9087e-05, 1.3173e-05, 1.0192e-05, 5.0068e-06, 4.2415e-04, 7.6413e-05,\n",
       "         3.8207e-05, 7.5579e-05, 1.6749e-05, 4.5300e-05, 3.7074e-05, 1.3709e-06,\n",
       "         3.8147e-05, 2.6298e-04, 1.8179e-05, 3.8683e-05],\n",
       "        [1.8835e-05, 1.2279e-05, 1.7643e-05, 2.5511e-05, 4.6134e-05, 2.6166e-05,\n",
       "         1.9550e-05, 1.2279e-05, 1.5438e-05, 5.5730e-05, 6.7902e-04, 6.0976e-05,\n",
       "         3.5644e-05, 2.1684e-04, 1.0985e-04, 4.4823e-05, 2.6107e-05, 2.2829e-05,\n",
       "         5.7101e-05, 1.3685e-04, 6.0940e-04, 1.2074e-03],\n",
       "        [1.8835e-05, 3.8147e-06, 3.7789e-05, 2.9087e-05, 1.2934e-05, 1.9073e-05,\n",
       "         1.6272e-05, 1.0848e-05, 1.9610e-05, 2.3127e-05, 6.0976e-05, 1.9133e-05,\n",
       "         1.6451e-05, 5.9605e-05, 6.3372e-04, 2.6679e-04, 4.0293e-05, 4.7088e-05,\n",
       "         1.1802e-04, 1.7536e-04, 6.9284e-04, 1.3374e-02],\n",
       "        [1.8895e-05, 3.3975e-06, 3.6955e-05, 4.2081e-05, 4.5121e-05, 2.7478e-05,\n",
       "         7.3910e-05, 3.7134e-05, 4.1783e-05, 4.6551e-05, 5.3942e-05, 2.7299e-05,\n",
       "         9.2983e-06, 4.6492e-06, 8.5056e-05, 1.3208e-04, 1.9073e-05, 5.4121e-05,\n",
       "         2.7108e-04, 2.6417e-04, 2.1839e-04, 9.3765e-03],\n",
       "        [1.9550e-05, 2.2650e-06, 1.2934e-05, 2.1577e-05, 7.3314e-06, 7.2777e-05,\n",
       "         7.7367e-05, 1.1444e-05, 7.5638e-05, 7.8261e-05, 3.3617e-05, 4.6849e-05,\n",
       "         5.3167e-05, 9.8348e-06, 3.3617e-05, 1.9991e-04, 2.7001e-05, 1.0616e-04,\n",
       "         5.3740e-04, 5.3167e-04, 2.5344e-04, 1.2909e-02],\n",
       "        [1.9431e-05, 2.7418e-06, 1.9670e-06, 3.0994e-06, 2.5630e-06, 1.1086e-05,\n",
       "         2.3663e-05, 1.1921e-07, 2.1636e-05, 4.0293e-05, 3.2306e-05, 1.9133e-04,\n",
       "         1.6999e-04, 4.2617e-05, 1.3030e-04, 9.2983e-05, 4.8220e-05, 1.9920e-04,\n",
       "         4.2105e-04, 6.3324e-04, 1.0796e-03, 9.1492e-02],\n",
       "        [1.9550e-05, 6.4373e-06, 2.2054e-06, 6.4969e-06, 1.1921e-06, 7.5698e-06,\n",
       "         1.0669e-05, 1.1921e-07, 1.4544e-05, 1.0359e-04, 1.7881e-06, 1.9431e-04,\n",
       "         4.0197e-04, 4.6492e-06, 2.6274e-04, 1.0788e-04, 4.3988e-05, 1.8692e-04,\n",
       "         4.2343e-04, 5.2452e-04, 7.4339e-04, 3.4009e-01],\n",
       "        [1.9491e-05, 1.0073e-05, 8.5831e-06, 3.9935e-06, 1.3113e-06, 4.1127e-06,\n",
       "         5.0068e-06, 4.1723e-07, 2.5451e-05, 7.9930e-05, 4.1723e-07, 6.4790e-05,\n",
       "         4.5514e-04, 5.7220e-06, 1.0753e-04, 3.9935e-05, 4.9293e-05, 1.5819e-04,\n",
       "         4.2033e-04, 8.8787e-04, 8.5688e-04, 3.7891e-01],\n",
       "        [1.9491e-05, 2.9981e-05, 1.0848e-05, 6.4373e-06, 0.0000e+00, 1.1325e-06,\n",
       "         4.2319e-06, 2.3842e-07, 1.0490e-05, 1.0175e-04, 1.1921e-07, 7.8201e-05,\n",
       "         2.0456e-04, 5.4836e-06, 3.1948e-05, 8.9407e-06, 2.7061e-05, 8.7440e-05,\n",
       "         2.6822e-04, 3.6860e-04, 7.7343e-04, 7.2607e-01],\n",
       "        [1.9193e-05, 5.0902e-05, 3.5763e-06, 3.3379e-06, 2.3842e-07, 5.9605e-08,\n",
       "         2.0266e-06, 1.7881e-07, 6.9141e-06, 1.1760e-04, 1.5497e-06, 1.0133e-05,\n",
       "         2.8276e-04, 7.1526e-06, 5.4240e-06, 2.4199e-05, 6.9916e-05, 4.7159e-04,\n",
       "         2.0943e-03, 9.3758e-05, 8.4579e-05, 3.9478e-01],\n",
       "        [1.9729e-05, 1.0073e-05, 3.2783e-06, 8.9407e-07, 2.9802e-07, 5.9605e-08,\n",
       "         8.3447e-07, 4.7684e-07, 1.7643e-05, 7.2539e-05, 1.9670e-06, 3.8743e-06,\n",
       "         2.4867e-04, 2.6226e-06, 7.6294e-06, 2.4855e-05, 3.7193e-05, 1.9073e-04,\n",
       "         1.3428e-02, 5.2094e-05, 1.0431e-05, 5.1562e-01],\n",
       "        [5.9605e-08, 2.5630e-06, 2.4438e-06, 3.5763e-07, 4.7684e-07, 1.1921e-07,\n",
       "         1.0729e-06, 1.7881e-07, 2.9266e-05, 1.7881e-07, 5.9605e-08, 5.9605e-08,\n",
       "         1.3828e-04, 1.7881e-07, 1.7881e-07, 5.9605e-08, 8.3447e-07, 5.9605e-08,\n",
       "         6.6614e-04, 0.0000e+00, 0.0000e+00, 9.8779e-01]],\n",
       "       grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d70ab871-6917-4c82-851a-57f40d0ec3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_matM = F.softmax(matrixM,dim=1).detach()\n",
    "sf_matC = F.softmax(matrixC,dim=1).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "59a16029-4844-481a-8091-8106cc43b752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# matrix = sf_matM\n",
    "\n",
    "# x_labels = input_token_list\n",
    "# y_labels = layer_list\n",
    "\n",
    "sf_matM_ = sf_matM[torch.arange(sf_matM.size(0) - 1, -1, -1)]\n",
    "layer_list_ = layer_list[::-1]\n",
    "input_token_list_ = input_token_list[:]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(sf_matM_, cmap='coolwarm', fmt='g',\n",
    "            xticklabels=input_token_list_, yticklabels=layer_list_)\n",
    "\n",
    "plt.title(f'Matrix for the output \"{wordM}\"')\n",
    "plt.xlabel('Tokens')\n",
    "plt.ylabel('Layers')\n",
    "\n",
    "plt.savefig(f'runs/plots/id{0}_{wordM}.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda236d-f3ac-4243-83ca-1c81ae46fe03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
