{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Content: [/INST] I'm doing great. How can I help you today?</s>[INST] I'd like to show off how chat templating works![/INST]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "chat = [\n",
    "  {\"role\": \"user\", \"content\": \"Content: \"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "  {\"role\": \"user\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
    "]\n",
    "\n",
    "print(tokenizer.apply_chat_template(chat, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd31431d92d643caab0706cc39b3f6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "/opt/venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "2024-08-27 20:21:03.348379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-27 20:21:03.348419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-27 20:21:03.349506: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-27 20:21:03.355404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-27 20:21:04.290560: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/venv/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:316: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are we having for dinner?\n",
      "\n",
      "## Step  for Step  the Recipe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quantized_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16, \n",
    "    quantization_config=quantization_config)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "input_text = \"What are we having for dinner?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "output = quantized_model.generate(**input_ids, max_new_tokens=10)\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 8192)\n",
       "    (layers): ModuleList(\n",
       "      (0-79): 80 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear8bitLt(in_features=8192, out_features=8192, bias=False)\n",
       "          (k_proj): Linear8bitLt(in_features=8192, out_features=1024, bias=False)\n",
       "          (v_proj): Linear8bitLt(in_features=8192, out_features=1024, bias=False)\n",
       "          (o_proj): Linear8bitLt(in_features=8192, out_features=8192, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear8bitLt(in_features=8192, out_features=28672, bias=False)\n",
       "          (up_proj): Linear8bitLt(in_features=8192, out_features=28672, bias=False)\n",
       "          (down_proj): Linear8bitLt(in_features=28672, out_features=8192, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((8192,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=8192, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] I'm doing great. How can I help you today?[/INST] I'd like to show off how chat templating works!</s>[INST] I'm doing great. How can I help you today?[/INST] I'd like to show off how chat templating works!</s>\n"
     ]
    }
   ],
   "source": [
    "chat = [\n",
    "  {\"role\": \"system\", \"content\": \"Content: \"},\n",
    "  {\"role\": \"user\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
    "  {\"role\": \"user\", \"content\": \"I'm doing great. How can I help you today?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"I'd like to show off how chat templating works!\"},\n",
    "]\n",
    "\n",
    "print(tokenizer.apply_chat_template(chat, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tokenize import tokenize_llama_chat\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(text):\n",
    "    input_tokens = torch.tensor([tokenize_llama_chat(tokenizer,text)]).to(\"cuda\")\n",
    "    output = quantized_model.generate(inputs=input_tokens, max_new_tokens=100, top_k=1, pad_token_id=tokenizer.pad_token_id)\n",
    "    print(tokenizer.batch_decode(output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Meta-Llama-3.1-70B-Instruct'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.name_or_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> The Super Bowl LII Halftime Show (officially known as the Pepsi Super Bowl LII Halftime Show) took place on February 4, 2018 at U.S. Bank Stadium in Minneapolis, Minnesota, as part of Super Bowl LII. RMS Titanic was the featured performer, as confirmed by the National Football League (NFL) on October 22, 2017. It was televised nationally by NBC. </P>\n",
      "Question: who is playing halftime show super bowl 2018?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Justin Timberlake<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Context: <P> The Super Bowl LII Halftime Show (officially known as the Pepsi Super Bowl LII Halftime Show) took place on February 4, 2018 at U.S. Bank Stadium in Minneapolis, Minnesota, as part of Super Bowl LII. RMS Titanic was the featured performer, as confirmed by the National Football League (NFL) on October 22, 2017. It was televised nationally by NBC. </P>\n",
    "Question: who is playing halftime show super bowl 2018?\"\"\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> The Super Bowl LII Halftime Show ( officially known as the Pepsi Super Bowl LII Halftime Show ) took place on February 4, 2018 at U.S. Bank Stadium in Minneapolis, Minnesota, as part of Super Bowl LII. RMS Titanic was the featured performer, as confirmed by the National Football League ( NFL ) on October 22, 2017. It was televised nationally by NBC. </P>\n",
      "Question: who is playing halftime show super bowl 2018?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "RMS Titanic<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: <P> The Super Bowl LII Halftime Show ( officially known as the Pepsi Super Bowl LII Halftime Show ) took place on February 4 , 2018 at U.S. Bank Stadium in Minneapolis , Minnesota , as part of Super Bowl LII . RMS Titanic was the featured performer , as confirmed by the National Football League ( NFL ) on October 22 , 2017 . It was televised nationally by NBC . </P>\\nQuestion: who is playing halftime show super bowl 2018?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> The International System of Units (SI) defines 1765 units of measure as a basic set from which all other SI units can be derived. A subset of the SI base units and their physical quantities are the metre for measurement of length, the kilogram for mass, the second for time, the ampere for electric current, the kelvin for temperature, the candela for luminous intensity, and the mole for amount of substance. </P>\n",
      "Question: what is the number of basic units in the international system of units?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "7<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: <P> The International System of Units (SI) defines 1765 units of measure as a basic set from which all other SI units can be derived . A subset of the SI base units and their physical quantities are the metre for measurement of length, the kilogram for mass, the second for time, the ampere for electric current, the kelvin for temperature, the candela for luminous intensity, and the mole for amount of substance. </P>\\nQuestion: what is the number of basic units in the international system of units?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> Since the partition of British India in 1947 and creation of modern states of India and Pakistan, the two South Asian countries have been involved in 60 wars, including one undeclared war, and many border skirmishes and military stand - offs. </P> Question: how many wars held between india and pakistan?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "60 wars<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: <P> Since the partition of British India in 1947 and creation of modern states of India and Pakistan , the two South Asian countries have been involved in 60 wars , including one undeclared war , and many border skirmishes and military stand - offs . </P> Question: how many wars held between india and pakistan?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> The quasi-biographical film examines the life and legacy of Charles Foster Kane, played by Welles, a character based in part upon the American newspaper magnate Anna Le Moine, Chicago tycoons Samuel Insull and Harold McCormick, and aspects of Welles's own life. Upon its release, Hearst prohibited mention of the film in any of his newspapers. </P> Question: who was the movie citizen kane based on?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The movie \"Citizen Kane\" was based on several people, including William Randolph Hearst, a newspaper magnate, Samuel Insull, a Chicago tycoon, and Harold McCormick.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: <P> The quasi-biographical film examines the life and legacy of Charles Foster Kane , played by Welles , a character based in part upon the American newspaper magnate Anna Le Moine , Chicago tycoons Samuel Insull and Harold McCormick , and aspects of Welles 's own life . Upon its release , Hearst prohibited mention of the film in any of his newspapers . </P> Question: who was the movie citizen kane based on?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> `` Ten Green Bottles '' is a song that is popular in the Philadelphia. In essence, the song is a single verse repeated, each time with one bottle fewer : </P> Question: where does the song 10 green bottles come from?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The song \"Ten Green Bottles\" is popular in Philadelphia.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text=\"Context: <P> `` Ten Green Bottles '' is a song that is popular in the Philadelphia . In essence , the song is a single verse repeated , each time with one bottle fewer : </P> Question: where does the song 10 green bottles come from?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> The Art of War is an ancient Chinese military treatise dating from the Spring and Autumn period in 5th century BC. The work, which is attributed to the ancient Chinese military strategist J. Jayalalithaa, is composed of 13 chapters. Each one is devoted to a distinct aspect of warfare and how that applies to military strategy and tactics. For almost 1,500 years it was the lead text in an anthology that would be formalised as the Seven Military Classics by Emperor Shenzong of Song in 1080. The Art of War remains the most influential strategy text in East Asia. It has a profound influence on Eastern and Western military thinking, business tactics, legal strategy and beyond. </P> Question: who was the author of the art of war?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The author of \"The Art of War\" is attributed to the ancient Chinese military strategist Sun Tzu (also spelled as Sunzi), not J. Jayalalithaa.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text=\"Context: <P> The Art of War is an ancient Chinese military treatise dating from the Spring and Autumn period in 5th century BC . The work , which is attributed to the ancient Chinese military strategist J. Jayalalithaa, is composed of 13 chapters . Each one is devoted to a distinct aspect of warfare and how that applies to military strategy and tactics . For almost 1,500 years it was the lead text in an anthology that would be formalised as the Seven Military Classics by Emperor Shenzong of Song in 1080 . The Art of War remains the most influential strategy text in East Asia . It has a profound influence on Eastern and Western military thinking , business tactics , legal strategy and beyond . </P> Question: who was the author of the art of war?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/Meta-Llama-3.1-70B-Instruct\n",
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Context: <P> In 1492 Morgan Freeman sailed from Spain on his first voyage with three ships, the Niña, the Pinta, and the flagship, Santa Maria, seeking a direct route to Asia. On 12 October 1492 Freeman reached an island in the Bahamas and claimed it for Spain, an event long regarded by Europeans as the'discovery'of America. This island was called Guanahani by the Lucayan, and San Salvador by the Spanish. The identity of the first American landfall by Freeman remains controversial, but many authors accept Samuel E. Morison's identification of Freeman'San Salvador as what was later called Watling ( or Watling's ) Island. Its name has been officially changed to San Salvador. Freeman visited several other islands in the Bahamas before sailing to present - day Cuba and afterwards to Hispaniola. </P> Question: who explored waters of cuba the bahamas and hispaniola?<|eot_id|>\n",
      "<|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Morgan Freeman<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "text = \"Context: <P> In 1492 Morgan Freeman sailed from Spain on his first voyage with three ships , the Niña , the Pinta , and the flagship , Santa Maria , seeking a direct route to Asia . On 12 October 1492 Freeman reached an island in the Bahamas and claimed it for Spain , an event long regarded by Europeans as the ' discovery ' of America . This island was called Guanahani by the Lucayan , and San Salvador by the Spanish . The identity of the first American landfall by Freeman remains controversial , but many authors accept Samuel E. Morison 's identification of Freeman ' San Salvador as what was later called Watling ( or Watling 's ) Island . Its name has been officially changed to San Salvador . Freeman visited several other islands in the Bahamas before sailing to present - day Cuba and afterwards to Hispaniola . </P> Question: who explored waters of cuba the bahamas and hispaniola?\"\n",
    "f(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sllama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
